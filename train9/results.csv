                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                0.66342,                0.46154,                      1,                0.70005,               7.14e-05,               7.14e-05,               7.14e-05
                      2,                 0.6161,                0.88462,                      1,                0.63354,             0.00014252,             0.00014252,             0.00014252
                      3,                0.54892,                      1,                      1,                 0.5383,             0.00020586,             0.00020586,             0.00020586
                      4,                0.46561,                0.98077,                      1,                0.46396,             0.00026143,             0.00026143,             0.00026143
                      5,                0.34842,                      1,                      1,                0.40859,             0.00030922,             0.00030922,             0.00030922
                      6,                0.28799,                0.96154,                      1,                0.38858,             0.00034924,             0.00034924,             0.00034924
                      7,                0.21326,                0.96154,                      1,                0.37003,             0.00038148,             0.00038148,             0.00038148
                      8,                0.24368,                      1,                      1,                0.33985,             0.00040594,             0.00040594,             0.00040594
                      9,                0.16785,                      1,                      1,                0.34156,             0.00042263,             0.00042263,             0.00042263
                     10,                0.19705,                      1,                      1,                0.32864,             0.00039591,             0.00039591,             0.00039591
                     11,                0.21604,                      1,                      1,                0.32392,             0.00039591,             0.00039591,             0.00039591
                     12,                0.12482,                      1,                      1,                0.32092,             0.00036057,             0.00036057,             0.00036057
                     13,                0.09885,                      1,                      1,                0.31956,             0.00032523,             0.00032523,             0.00032523
                     14,                0.07424,                      1,                      1,                0.31807,             0.00028988,             0.00028988,             0.00028988
                     15,                0.07288,                      1,                      1,                0.31779,             0.00025454,             0.00025454,             0.00025454
                     16,                0.11327,                      1,                      1,                0.31755,              0.0002192,              0.0002192,              0.0002192
                     17,                0.08388,                      1,                      1,                0.31849,             0.00018385,             0.00018385,             0.00018385
                     18,                0.10192,                      1,                      1,                0.31785,             0.00014851,             0.00014851,             0.00014851
                     19,                0.04881,                      1,                      1,                 0.3173,             0.00011317,             0.00011317,             0.00011317
                     20,                0.03711,                      1,                      1,                0.31629,             7.7826e-05,             7.7826e-05,             7.7826e-05
